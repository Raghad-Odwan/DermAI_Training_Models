{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghad-Odwan/DermAI_Training_Models/blob/main/DermAI_Model_Training_2ndTry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raghad.M**"
      ],
      "metadata": {
        "id": "DH5H4M5s0l_l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9j1mMPmK1C"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BZSwgpySG-f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnOEhTE2PYL8"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtSwYn7MR8jT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCfgt1ggPLpH"
      },
      "outputs": [],
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Preventing Colab timeout\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect, 60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujA-N-lvmNt_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJqf6nCNSK99"
      },
      "source": [
        "# **DermAI_AI_Model_Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvegU7jsUFOa"
      },
      "source": [
        "This Google Colab notebook has been prepared for the preparation and training of a machine learning model specialized in skin cancer detection.\n",
        "The model performs binary classification of skin lesion images into two categories: Benign and Malignant.\n",
        "\n",
        "\n",
        "### Dataset Source\n",
        "\n",
        "The dataset used in this project was collected from the following sources:\n",
        "(                  _____                )\n",
        "\n",
        "The dataset contains approximately 13,249 benign and 6,211 malignant images, providing a total of around 19,460 samples used for training, validation, and testing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Notebook Structure\n",
        "\n",
        "This notebook is organized into three main sections:\n",
        "\n",
        "**-Data Loading, Verification, and Preprocessing**\n",
        "\n",
        "This section focuses on importing the dataset, verifying its structure, cleaning inconsistencies, and performing Exploratory Data Analysis (EDA).\n",
        "Steps include resizing, normalization, data augmentation, and splitting the dataset into training, validation, and testing subsets.\n",
        "\n",
        "**-Model Training and Evaluation**\n",
        "\n",
        "In this section, a machine learning model is implemented and trained for skin lesion classification.\n",
        "The process includes model configuration, training, and performance evaluation using metrics such as accuracy, precision, recall, and F1-score.\n",
        "Optimization methods are also applied to ensure stable and efficient training.\n",
        "\n",
        "**-Result Interpretation and Visualization**\n",
        "\n",
        "This part is dedicated to analyzing the model’s predictions and interpreting its decision-making process using Grad-CAM and other visualization tools.\n",
        "It highlights how the model distinguishes between benign and malignant lesions, providing insights into reliability and interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PuzGd2ij6kK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Note: This notebook represents a core component of the DermAI Graduation Project at Palestine Technical University – Kadoorie.\n",
        "It aims to demonstrate the end-to-end process of building an intelligent, interpretable, and efficient system for skin cancer classification, contributing to early detection and supporting clinical decision-making.**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlNwr0kGmi-h"
      },
      "source": [
        "## 1. **Part One: Dataset Preparation & Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtslpsqEsU88"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VQSvLBtsbCJ"
      },
      "outputs": [],
      "source": [
        "# Define main dataset path\n",
        "base_dir = \"/content/drive/MyDrive/Dataset/Dataset\"\n",
        "folders = [\"benign\", \"malignant\"]\n",
        "\n",
        "print(\"Base directory:\", base_dir)\n",
        "for folder in folders:\n",
        "    path = os.path.join(base_dir, folder)\n",
        "    print(f\"{folder}: {len(os.listdir(path))} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ8eTjKisdq6"
      },
      "outputs": [],
      "source": [
        "# Create a folder for problematic images\n",
        "dup_dir = os.path.join(base_dir, \"duplicates_or_corrupted\")\n",
        "os.makedirs(dup_dir, exist_ok=True)\n",
        "print(\"Duplicate/Corrupted folder created at:\", dup_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO9lRiMgsjp1"
      },
      "outputs": [],
      "source": [
        "# Define an image cleaning class\n",
        "class ImageCleaner:\n",
        "    def __init__(self, base_path):\n",
        "        self.base_path = Path(base_path)\n",
        "        self.folders_to_check = ['benign', 'malignant']\n",
        "        self.problem_folder = self.base_path / 'duplicates_or_corrupted'\n",
        "        self.problem_folder.mkdir(exist_ok=True)\n",
        "        self.stats = {'total_checked': 0, 'corrupted': 0, 'duplicates': 0, 'low_quality': 0, 'healthy': 0}\n",
        "        self.image_hashes = defaultdict(list)\n",
        "\n",
        "    def calculate_hash(self, image_path):\n",
        "        import hashlib\n",
        "        try:\n",
        "            hasher = hashlib.md5()\n",
        "            with open(image_path, 'rb') as f:\n",
        "                buf = f.read()\n",
        "                hasher.update(buf)\n",
        "            return hasher.hexdigest()\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def is_image_corrupted(self, image_path):\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                img.verify()\n",
        "            return False\n",
        "        except:\n",
        "            return True\n",
        "\n",
        "    def check_image_quality(self, image_path, min_width=50, min_height=50):\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                width, height = img.size\n",
        "                if width < min_width or height < min_height:\n",
        "                    return False\n",
        "                if os.path.getsize(image_path) < 1000:\n",
        "                    return False\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def move_to_problem_folder(self, image_path):\n",
        "        try:\n",
        "            dest_subfolder = self.problem_folder / image_path.parent.name\n",
        "            dest_subfolder.mkdir(exist_ok=True)\n",
        "            shutil.move(str(image_path), str(dest_subfolder / image_path.name))\n",
        "        except Exception as e:\n",
        "            print(f\"Error moving {image_path.name}: {e}\")\n",
        "\n",
        "    def clean_folder(self, folder_name):\n",
        "        folder_path = self.base_path / folder_name\n",
        "        image_exts = ['.jpg', '.jpeg', '.png']\n",
        "        images = [f for f in folder_path.iterdir() if f.suffix.lower() in image_exts]\n",
        "        print(f\"Cleaning {folder_name} ({len(images)} images)...\")\n",
        "\n",
        "        for img_path in tqdm(images, desc=f\"Checking {folder_name}\"):\n",
        "            self.stats['total_checked'] += 1\n",
        "            if self.is_image_corrupted(img_path):\n",
        "                self.move_to_problem_folder(img_path)\n",
        "                self.stats['corrupted'] += 1\n",
        "                continue\n",
        "            if not self.check_image_quality(img_path):\n",
        "                self.move_to_problem_folder(img_path)\n",
        "                self.stats['low_quality'] += 1\n",
        "                continue\n",
        "            img_hash = self.calculate_hash(img_path)\n",
        "            if img_hash in self.image_hashes:\n",
        "                self.move_to_problem_folder(img_path)\n",
        "                self.stats['duplicates'] += 1\n",
        "            else:\n",
        "                self.image_hashes[img_hash].append(str(img_path))\n",
        "                self.stats['healthy'] += 1\n",
        "\n",
        "    def clean_all(self):\n",
        "        for folder in self.folders_to_check:\n",
        "            self.clean_folder(folder)\n",
        "        print(\"\\nCleaning Summary:\")\n",
        "        for k, v in self.stats.items():\n",
        "            print(f\"{k}: {v}\")\n",
        "\n",
        "# Run the cleaning process\n",
        "cleaner = ImageCleaner(base_dir)\n",
        "cleaner.clean_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Aa5ODGQs6NI"
      },
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "count_benign = len(os.listdir(os.path.join(base_dir, \"benign\")))\n",
        "count_malignant = len(os.listdir(os.path.join(base_dir, \"malignant\")))\n",
        "plt.bar([\"Benign\", \"Malignant\"], [count_benign, count_malignant])\n",
        "plt.title(\"Class Distribution After Cleaning\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuesJ_ALs8Cq"
      },
      "outputs": [],
      "source": [
        "# Resize all images to (224x224)\n",
        "IMG_SIZE = (224, 224)\n",
        "for cat in folders:\n",
        "    src_dir = os.path.join(base_dir, cat)\n",
        "    files = os.listdir(src_dir)\n",
        "    for fname in tqdm(files, desc=f\"Resizing {cat}\"):\n",
        "        path = os.path.join(src_dir, fname)\n",
        "        try:\n",
        "            img = cv2.imread(path)\n",
        "            if img is None: continue\n",
        "            resized = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
        "            cv2.imwrite(path, resized)\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXqP3MmYtJYu"
      },
      "outputs": [],
      "source": [
        "# Split dataset (70% train, 15% val, 15% test)\n",
        "split_dir = \"/content/ai/Dataset_split\"\n",
        "os.makedirs(split_dir, exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "for label in folders:\n",
        "    path = os.path.join(base_dir, label)\n",
        "    for fname in os.listdir(path):\n",
        "        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            rows.append({'path': os.path.join(path, fname), 'label': label})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "train_temp, test = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\n",
        "train, val = train_test_split(train_temp, test_size=0.1765, stratify=train_temp['label'], random_state=42)\n",
        "\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    for label in folders:\n",
        "        os.makedirs(os.path.join(split_dir, subset, label), exist_ok=True)\n",
        "\n",
        "def copy_images(df_subset, subset_name):\n",
        "    for _, row in tqdm(df_subset.iterrows(), total=len(df_subset), desc=f\"Copying {subset_name}\"):\n",
        "        dest = os.path.join(split_dir, subset_name, row['label'], os.path.basename(row['path']))\n",
        "        shutil.copy2(row['path'], dest)\n",
        "\n",
        "copy_images(train, \"train\")\n",
        "copy_images(val, \"val\")\n",
        "copy_images(test, \"test\")\n",
        "\n",
        "print(f\"\\nDataset split completed successfully!\")\n",
        "print(f\"Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BrWAksE227X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "####  Build DataFrame & Quick Integrity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARx5owga3By7"
      },
      "outputs": [],
      "source": [
        "# Count the number of image files in each class folder (benign and malignant)\n",
        "# This function walks through all subdirectories and counts only valid image files.\n",
        "import os, sys, traceback\n",
        "base_path = \"/content/drive/MyDrive/Dataset/Dataset\"\n",
        "\n",
        "def count_images_in_folder(folder):\n",
        "    exts = ('.jpg','.jpeg','.png','.bmp')\n",
        "    cnt = 0\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(exts):\n",
        "                cnt += 1\n",
        "    return cnt\n",
        "\n",
        "for cls in ['benign','malignant']:\n",
        "    p = os.path.join(base_path, cls)\n",
        "    if not os.path.exists(p):\n",
        "        print(f\" WARNING: folder not found: {p}\")\n",
        "    else:\n",
        "        print(f\"{cls}: {count_images_in_folder(p):,} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z8QjeKr30K-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "# build dataframe (paths + labels)\n",
        "rows=[]\n",
        "exts = ('.jpg','.jpeg','.png','.bmp')\n",
        "for cls in ['benign','malignant']:\n",
        "    folder = os.path.join(base_path, cls)\n",
        "    if not os.path.exists(folder):\n",
        "        continue\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for fname in files:\n",
        "            if fname.lower().endswith(exts):\n",
        "                rows.append({'path': os.path.join(root, fname), 'label': cls})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df['label_idx'] = df['label'].map({'benign':0, 'malignant':1})\n",
        "print(\"Total samples:\", len(df))\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dho8-d694E6j"
      },
      "outputs": [],
      "source": [
        "#  quick corrupted-files check (lightweight, may take time if dataset big)\n",
        "#  try to open the first N images from each class to detect obvious corruption\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "def check_samples(df, n_per_class=20):\n",
        "    corrupted = []\n",
        "    for cls in df['label'].unique():\n",
        "        paths = df[df['label']==cls]['path'].tolist()\n",
        "        sample_paths = random.sample(paths, min(n_per_class, len(paths)))\n",
        "        for p in sample_paths:\n",
        "            try:\n",
        "                img = Image.open(p)\n",
        "                img.verify()\n",
        "            except Exception as e:\n",
        "                corrupted.append((p, str(e)))\n",
        "    return corrupted\n",
        "\n",
        "corrupted_examples = check_samples(df, n_per_class=30)\n",
        "if corrupted_examples:\n",
        "    print(\" Found corrupted or unreadable sample(s):\", len(corrupted_examples))\n",
        "    for p,err in corrupted_examples[:5]:\n",
        "        print(\"-\", p, \"=>\", err)\n",
        "else:\n",
        "    print(\" Quick corrupted-sample check passed successfully (no issues in sampled files).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX7JGCIv4dht"
      },
      "outputs": [],
      "source": [
        "# Save metadata CSV\n",
        "out_csv = \"/content/drive/MyDrive/ai/data/df_metadata.csv\"\n",
        "os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(\" Metadata saved to:\", out_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X8S6Okp6JrA"
      },
      "outputs": [],
      "source": [
        "display(df.head(10))\n",
        "print(\"\\nCounts (sanity):\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY4uoFC17E4w"
      },
      "outputs": [],
      "source": [
        "# Quick test reading data\n",
        "# Randomly load and display one sample image from the dataset\n",
        "# to verify that image paths are correct and preprocessing worked properly.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample = random.choice(df['path'].tolist())\n",
        "img = image.load_img(sample, target_size=(224,224))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(sample.split('/')[-2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exo-cHl6Ce_n"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj7gChfDChNO"
      },
      "source": [
        "## **Part Two: Model Training and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8hnWIppDKDF"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os, math, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "# Parameters\n",
        "# Defines image size, batch size, epochs, and model saving directory\n",
        "DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "DF_PATH = os.path.join(DRIVE_BASE, \"ai/data/df_metadata.csv\")\n",
        "MODELS_DIR = os.path.join(DRIVE_BASE, \"DermAI_models_resnet\")\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "N_FOLDS = 3\n",
        "RANDOM_STATE = 42\n",
        "VERBOSE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3NIU_7RESJF"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_emNvBXnEcr0"
      },
      "outputs": [],
      "source": [
        "# Read & Inspect Metadata\n",
        "meta_csv = \"/content/drive/MyDrive/ai/data/df_metadata.csv\"\n",
        "df = pd.read_csv(meta_csv)\n",
        "\n",
        "print(\"Loaded df:\", meta_csv)\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "display(df.head(10))\n",
        "\n",
        "# Prepare X and y for training\n",
        "X = df['path'].values\n",
        "y = df['label_idx'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5N0CPqKE9Ms"
      },
      "source": [
        "Data Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNTmqGopho8M"
      },
      "source": [
        "Prepare image generators for training and validation.\n",
        "Training generator applies data augmentation to improve model generalization, while validation generator only rescales pixel values.\n",
        "Tralies moderate augmentation; validation only rescales.ining generator app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKyxJfbVFAhQ"
      },
      "outputs": [],
      "source": [
        "# Data Generators\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Augmentation - General benign\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.85, 1.15],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# Augmentation - malignant\n",
        "train_malignant_datagen = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.25,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    contrast_stretching=True,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYJjSx-Ky7yh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsmmzHpuy93r"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMDmGUZ8Fy7q"
      },
      "source": [
        "Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkR6aL9QFxkH"
      },
      "outputs": [],
      "source": [
        "# Build ResNet50\n",
        "# binary classifier with fine-tuning of the last N layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_resnet_binary(input_shape=(224,224,3), unfreeze_last_n=40):\n",
        "    # Load base ResNet50\n",
        "    base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze all layers initially\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Unfreeze last N layers (except BatchNorm layers for training stability)\n",
        "    for layer in base.layers[-unfreeze_last_n:]:\n",
        "        if 'batch_normalization' in layer.name:\n",
        "            layer.trainable = False\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Add custom classification head\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Final output layer\n",
        "    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs=base.input, outputs=outputs)\n",
        "\n",
        "    # Compile the model with AdamW optimizer\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.experimental.AdamW(\n",
        "            learning_rate=1e-4,\n",
        "            weight_decay=1e-4\n",
        "        ),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzHe6mtGMfF"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiAGg0FDdM15"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCiRJ5_UxN9Y"
      },
      "outputs": [],
      "source": [
        "# Utility Functions for Dataset Loading & Preprocessing\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "def compute_weights(y_array):\n",
        "    classes = np.unique(y_array)\n",
        "    cw = compute_class_weight('balanced', classes=classes, y=y_array)\n",
        "    return {int(c): float(w) for c,w in zip(classes, cw)}\n",
        "\n",
        "def print_generator_info(gen, name=\"generator\"):\n",
        "    print(f\"{name} class_indices:\", getattr(gen, 'class_indices', None))\n",
        "    if hasattr(gen, 'classes'):\n",
        "        u,c = np.unique(gen.classes, return_counts=True)\n",
        "        print(f\"{name} counts:\", dict(zip(u,c)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNYik4jNowX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epO8C1qSNqN1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hl0uH_ho8Z"
      },
      "source": [
        "For each fold:\n",
        "• Split data into training and validation subsets while preserving class balance.\n",
        "• Build and train a ResNet50 model on the training subset.\n",
        "• Evaluate model performance on the validation subset (Accuracy, Precision, Recall, F1).\n",
        "• Save best model weights and record per-fold metrics.\n",
        "And after that Results from all folds are stored in 'fold_metrics' for later summary and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJidgjQUGN7n"
      },
      "outputs": [],
      "source": [
        "import math, gc, os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ai/data/df_metadata.csv')\n",
        "df_cv = df.copy()\n",
        "\n",
        "x = df_cv['path'].values\n",
        "y = df_cv['label_idx'].values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "splits = list(skf.split(X, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5GAf2sKUUtEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ydoc8ko1UvZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "NCvV1kmTVL8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save results\n",
        "SAVE_DIR = \"/content/drive/MyDrive/DermAI_results_evaluation\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "kWy45kqiTlA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, fold):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - Fold {fold}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.savefig(f\"{SAVE_DIR}/cm_fold{fold}.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "# ROC Curve\n",
        "def plot_roc_curve(y_true, y_pred_prob, fold):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "    plt.plot([0,1], [0,1], linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - Fold {fold}')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{SAVE_DIR}/roc_fold{fold}.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "# Accuracy & Loss\n",
        "def plot_training_curves(history, fold):\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(history.history['accuracy'], label='Train')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title(f'Fold {fold} - Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{SAVE_DIR}/acc_fold{fold}.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    # Loss\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(history.history['loss'], label='Train')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title(f'Fold {fold} - Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{SAVE_DIR}/loss_fold{fold}.png\", dpi=200)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "Tp0-URvOU0Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SRV-p4ozUw9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fold 1"
      ],
      "metadata": {
        "id": "NY05V3Zpv2d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fold 1\n",
        "# Model Training\n",
        "fold_no = 1\n",
        "train_idx, val_idx = splits[0]\n",
        "train_df = pd.DataFrame({'path': X[train_idx], 'label_idx': y[train_idx]})\n",
        "val_df   = pd.DataFrame({'path': X[val_idx],   'label_idx': y[val_idx]})\n",
        "\n",
        "class_weight = compute_weights(train_df['label_idx'].values)\n",
        "print(\"class_weight:\", class_weight)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(train_df, x_col='path', y_col='label_idx',\n",
        "                                              target_size=IMG_SIZE, class_mode='raw',\n",
        "                                              batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_gen = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label_idx',\n",
        "                                          target_size=IMG_SIZE, class_mode='raw',\n",
        "                                          batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print_generator_info(train_gen, \"train_gen\")\n",
        "print_generator_info(val_gen, \"val_gen\")\n",
        "\n",
        "model = build_resnet_binary(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), unfreeze_last_n=40)\n",
        "\n",
        "ckpt_path = os.path.join(MODELS_DIR, f\"best_resnet_fold{fold_no}.keras\")\n",
        "csv_log_path = os.path.join(MODELS_DIR, f\"training_log_fold{fold_no}.csv\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    CSVLogger(csv_log_path)\n",
        "]\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "best = tf.keras.models.load_model(ckpt_path)\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label_idx',\n",
        "                                               target_size=IMG_SIZE, class_mode='raw',\n",
        "                                               batch_size=BATCH_SIZE, shuffle=False)\n",
        "preds_prob = best.predict(val_gen_eval, steps=val_steps, verbose=VERBOSE)\n",
        "preds = (preds_prob.ravel() > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec = recall_score(true, preds, zero_division=0)\n",
        "f1 = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"Fold {fold_no} -> acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(true, preds))\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "nrH4kmMFv1cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Summary\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "val_pred = (val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Save plots for this fold\n",
        "plot_training_curves(history, fold_no)\n",
        "plot_roc_curve(val_df[\"label\"].values, val_pred_prob, fold_no)\n",
        "plot_confusion_matrix(val_df[\"label\"].values, val_pred, fold_no)"
      ],
      "metadata": {
        "id": "4kYSTC-Bygi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fold 2"
      ],
      "metadata": {
        "id": "Yd9-IVpUwMle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fold 2\n",
        "fold_no = 2\n",
        "train_idx, val_idx = splits[1]\n",
        "train_df = pd.DataFrame({'path': X[train_idx], 'label_idx': y[train_idx]})\n",
        "val_df   = pd.DataFrame({'path': X[val_idx],   'label_idx': y[val_idx]})\n",
        "\n",
        "class_weight = compute_weights(train_df['label_idx'].values)\n",
        "print(\"class_weight:\", class_weight)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(train_df, x_col='path', y_col='label_idx',\n",
        "                                              target_size=IMG_SIZE, class_mode='raw',\n",
        "                                              batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_gen = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label_idx',\n",
        "                                          target_size=IMG_SIZE, class_mode='raw',\n",
        "                                          batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print_generator_info(train_gen, \"train_gen\")\n",
        "print_generator_info(val_gen, \"val_gen\")\n",
        "\n",
        "model = build_resnet_binary(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), unfreeze_last_n=40)\n",
        "\n",
        "ckpt_path = os.path.join(MODELS_DIR, f\"best_resnet_fold{fold_no}.keras\")\n",
        "csv_log_path = os.path.join(MODELS_DIR, f\"training_log_fold{fold_no}.csv\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    CSVLogger(csv_log_path)\n",
        "]\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "best = tf.keras.models.load_model(ckpt_path)\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label_idx',\n",
        "                                               target_size=IMG_SIZE, class_mode='raw',\n",
        "                                               batch_size=BATCH_SIZE, shuffle=False)\n",
        "preds_prob = best.predict(val_gen_eval, steps=val_steps, verbose=VERBOSE)\n",
        "preds = (preds_prob.ravel() > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec = recall_score(true, preds, zero_division=0)\n",
        "f1 = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"Fold {fold_no} -> acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(true, preds))\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "2zIWd4ozwFnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Summary\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "val_pred = (val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Save plots for this fold\n",
        "plot_training_curves(history, fold_no)\n",
        "plot_roc_curve(val_df[\"label\"].values, val_pred_prob, fold_no)\n",
        "plot_confusion_matrix(val_df[\"label\"].values, val_pred, fold_no)"
      ],
      "metadata": {
        "id": "y6-b8VSbywWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fold 3"
      ],
      "metadata": {
        "id": "AM5sliyJwWwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fold 3\n",
        "fold_no = 3\n",
        "train_idx, val_idx = splits[2]\n",
        "train_df = pd.DataFrame({'path': X[train_idx], 'label_idx': y[train_idx]})\n",
        "val_df   = pd.DataFrame({'path': X[val_idx],   'label_idx': y[val_idx]})\n",
        "\n",
        "class_weight = compute_weights(train_df['label_idx'].values)\n",
        "print(\"class_weight:\", class_weight)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(train_df, x_col='path', y_col='label_idx',\n",
        "                                              target_size=IMG_SIZE, class_mode='raw',\n",
        "                                              batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_gen = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label_idx',\n",
        "                                          target_size=IMG_SIZE, class_mode='raw',\n",
        "                                          batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print_generator_info(train_gen, \"train_gen\")\n",
        "print_generator_info(val_gen, \"val_gen\")\n",
        "\n",
        "model = build_resnet_binary(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), unfreeze_last_n=40)\n",
        "\n",
        "ckpt_path = os.path.join(MODELS_DIR, f\"best_resnet_fold{fold_no}.keras\")\n",
        "csv_log_path = os.path.join(MODELS_DIR, f\"training_log_fold{fold_no}.csv\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    CSVLogger(csv_log_path)\n",
        "]\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "best = tf.keras.models.load_model(ckpt_path)\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label_idx',\n",
        "                                               target_size=IMG_SIZE, class_mode='raw',\n",
        "                                               batch_size=BATCH_SIZE, shuffle=False)\n",
        "preds_prob = best.predict(val_gen_eval, steps=val_steps, verbose=VERBOSE)\n",
        "preds = (preds_prob.ravel() > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec = recall_score(true, preds, zero_division=0)\n",
        "f1 = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"Fold {fold_no} -> acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "print(classification_report(true, preds, target_names=['benign','malignant'], zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(true, preds))\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Q_Sga86HwaaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Summary\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "val_pred = (val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Save plots for this fold\n",
        "plot_training_curves(history, fold_no)\n",
        "plot_roc_curve(val_df[\"label\"].values, val_pred_prob, fold_no)\n",
        "plot_confusion_matrix(val_df[\"label\"].values, val_pred, fold_no)"
      ],
      "metadata": {
        "id": "KAI52erNyyGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzmU9P548MXe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-zhlHge8N7c"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-j18g1V8PQn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnxMPbhHho8d"
      },
      "source": [
        "### Part Three"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AvegU7jsUFOa"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}